### Звіт про дослідження #2: Порівняльний аналіз pretrained моделей комп'ютерного зору для виявлення бізнес-релевантних об'єктів та ситуацій у візуальному контенті соціальних мереж

## 1. Контекст дослідження

### 1.1. Попередній етап
На попередньому етапі було проведено аналіз базового набору даних та виконано перший з трьох основних експериментів з порівняння та оптимізації моделей комп'ютерного зору. В результаті для подальшого дослідження було обрано модель SigLIP V2 (надалі просто SigLiP), яка показала найкращий результат серед усіх моделей в порівнянні: F1-Score (0.867) і одночасно задовольнила бізнес-вимогу (пріоритет точності над реколом при збереженні високого реколу більше або рівного 0.8), показавши Precision = 0.925 при Recall = 0.820.

### 1.2. Другий експеримент: Мультикласова класифікація

Метою другого експерименту стала перевірка найкращої розробленої моделі (SigLIP) на більш складному мультикласовому датасеті.

**Модель та датасет:**
- **Датасет**: Було створено новий мультикласовий набір даних
- **Категорії**: 5 класів (4 бізнес-категорії + 1 "Irrelevant")
- **Розмір**: 500 зображень (Support) на кожен клас (загалом 2500 зображень)
- **Модель**: `siglip_classifier.py` 

Різниця з першим експериментом полягає у функції активації та способі прийняття рішень. У першому експерименті (бінарна класифікація) модель працювала за принципом Sigmoid. Кожна бізнес-категорія ("Catering", "Pets" тощо) оцінювалася незалежно. Кожна з них отримувала окремий бал від 0 до 1. У другому експерименті (мультикласова класифікація) модель SigLIP, як і раніше, використовує Sigmoid для отримання незалежних балів (scores) для кожного з 5 класів. Рішення приймається шляхом вибору класу з найвищим балом (argmax), з подальшою пороговою фільтрацією.

## 2. Результати мультикласової оцінки

### 2.1. Базова модель (siglip_multiclass)

Результати базової моделі демонструють високу здатність ідентифікувати бізнес-категорії (Average Recall = 0.9065), проте з помітною проблемою точності для окремих категорій. Найкращі показники спостерігаються для класу Pet-Friendly Services (Precision = 0.9435, Recall = 0.9360), що свідчить про чітку візуальну відмінність цієї категорії. Водночас категорії Catering та Cultural_Excursions показують нижчу точність (0.7611 та 0.7540 відповідно), що може бути пов'язано з візуальною схожістю їхнього контенту з нерелевантними зображеннями.

**Загальні метрики:**
- Overall Accuracy: 0.7904
- Macro F1: 0.7712
- Average Precision для 4 бізнес-категорій: 0.8154
- Average Recall для 4 бізнес-категорій: 0.9065

**Результати по класах:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Catering | 0.7611 | 0.9560 | 0.8475 | 500 |
| Marine_Activities | 0.8029 | 0.8880 | 0.8433 | 500 |
| Cultural_Excursions | 0.7540 | 0.8460 | 0.7974 | 500 |
| Pet-Friendly Services | 0.9435 | 0.9360 | 0.9398 | 500 |
| Irrelevant | 0.6221 | 0.3260 | 0.4278 | 500 |

**Матриця плутанини:**

Ground Truth (rows) vs Predicted (columns)
|  | Catering | Marine_Act | Cultural_E | Pet-Friend | Irrelevant |
|---|----------|------------|------------|------------|------------|
| **Catering** | 478 | 3 | 3 | 0 | 16 |
| **Marine_Activities** | 9 | 444 | 22 | 0 | 25 |
| **Cultural_Excursions** | 7 | 19 | 423 | 0 | 51 |
| **Pet-Friendly Services** | 8 | 7 | 10 | 468 | 7 |
| **Irrelevant** | 126 | 80 | 103 | 28 | 163 |

**Виявлена сутттєва проблема:**

Незважаючи на високий Recall для бізнес-категорій (0.9065), спостерігається суттєво нижча точність (Precision = 0.8154). Це означає, що модель схильна до помилкової класифікації нерелевантного контенту як бізнес-категорій. Матриця плутанини чітко демонструє цю проблему: 337 з 500 Irrelevant зображень були помилково класифіковані як різні бізнес-категорії. 

Така поведінка моделі є неприйнятною для бізнес-завдання, оскільки генерує значний обсяг хибних спрацювань та знижує довіру до рекомендаційної системи.

### 2.2. Дослідження порогової фільтрації

Для вирішення проблеми помилкової класифікації Irrelevant контенту було проведено дослідження впливу порогової фільтрації. Підхід полягав у наступному: якщо бізнес-клас ідентифікувався моделлю "не досить впевнено" - зі скором нижче за певний поріг, такий об'єкт примусово класифікувався як нерелевантний.

**Результати підбору порогу:**

| Threshold | F1 | Accuracy | Precision*| Recall*|
|-----------|----|----------|-----------|--------|
| 0.000000**| 0.7712 | 0.7904 | 0.8154 | 0.9065 |
| 0.000010 | 0.7931 | 0.7788 | 0.9158 | 0.7745 |
| 0.000020 | 0.7548 | 0.7328 | 0.9252 | 0.7075 |
| 0.000030 | 0.7286 | 0.7024 | 0.9270 | 0.6670 |
| 0.000040 | 0.7099 | 0.6808 | 0.9330 | 0.6365 |
| 0.000050 | 0.6968 | 0.6660 | 0.9369 | 0.6145 |
| 0.000060 | 0.6825 | 0.6508 | 0.9400 | 0.5920 |
| 0.000070 | 0.6697 | 0.6372 | 0.9415 | 0.5735 |
| 0.000080 | 0.6621 | 0.6292 | 0.9448 | 0.5615 |
| 0.000090 | 0.6518 | 0.6188 | 0.9468 | 0.5460 |

'* - по 4х бізнес-класах

'** - це результат базової моделі на етапі 2.1, без фільрації.

Дослідження показало чітку закономірність: зі зростанням порогу Precision стабільно зростає (від 0.9158 до 0.9468), але Recall пропорційно знижується (від 0.7745 до 0.5460). Оптимальним було обрано поріг 0.000010, який забезпечує найкращий баланс (найвищий Macro F1-Score 0.7931) при збереженні високої точності (0.9158).

### 2.3. Модель з оптимальною фільтрацією (threshold = 0.000010)

Застосування фільтрації з порогом 0.000010 суттєво покращила результати.

**Ключові досягнення:**
- **Висока точність**: Середня точність (Average Precision) для 4 бізнес-категорій зросла до 0.9158 (порівняно з 0.8154 у базовій моделі)
- **Вирішення проблеми "Irrelevant"**: Модель почала коректно фільтрувати нерелевантний контент (Recall для класу Irrelevant зріс з 0.3260 до 0.7960)
- **Контрольований компроміс**: Це досягнення було отримано ціною зниження повноти (Average Recall) для бізнес-категорій (з 0.9065 до 0.7745)

Цей результат повністю відповідав поставленій бізнес-задачі: ми отримали модель, яка генерує надійні бізнес-сигнали (висока точність) ціною пропуску частини з них (прийнятний Recall).

**Загальні метрики:**
- Overall Accuracy: 0.7788
- Macro F1: 0.7931
- Average Precision для 4 бізнес-категорій: 0.9158
- Average Recall для 4 бізнес-категорій: 0.7745

**Результати по класах:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Catering | 0.8776 | 0.7600 | 0.8146 | 500 |
| Marine_Activities | 0.9259 | 0.8000 | 0.8584 | 500 |
| Cultural_Excursions | 0.8674 | 0.7460 | 0.8022 | 500 |
| Pet-Friendly Services | 0.9925 | 0.7920 | 0.8810 | 500 |
| Irrelevant | 0.4938 | 0.7960 | 0.6095 | 500 |

**Матриця плутанини:**

Ground Truth (rows) vs Predicted (columns)
|  | Catering | Marine_Act | Cultural_E | Pet-Friend | Irrelevant |
|---|----------|------------|------------|------------|------------|
| **Catering** | 380 | 0 | 0 | 0 | 120 |
| **Marine_Activities** | 7 | 400 | 16 | 0 | 77 |
| **Cultural_Excursions** | 3 | 7 | 373 | 0 | 117 |
| **Pet-Friendly Services** | 4 | 6 | 0 | 396 | 94 |
| **Irrelevant** | 39 | 19 | 41 | 3 | 398 |

## 3. Висновки

Розроблений підхід - класифікація з допомогою моделі SigLIP з подальшої фільтрацією сигналів дозволяє мінімізувати шум і з високою точністю визначати саме необхідні бізнес-сигнали. Відносно невеликий рекол в межах 0.76-0.80 є прийнятним для бізнес-задачі, оскільки користувачі, зацікавлені в певній тематиці, постять в соц-мережах цікавий для них контент регулярно (не в одиничних екземплярах).

Порогова фільтрація з threshold = 0.000010 продемонструвала ефективність у вирішенні проблеми помилкової класифікації нерелевантного контенту, підвищивши середню точність бізнес-категорій на 12.3% (з 0.8154 до 0.9158) при збереженні прийнятного рівня повноти (0.7745).


### 3.2. Третій експеримент: Класифікація синтетичних профілів користувачів соц-медіа

Метою третього експерименту буде перевірити найкращу розроблену модель (SigLIP) на можливість класифікувати профілі користувачів соцмедіа.

**Модель та датасет:**
- **Датасет**: Буде створено новий набір даних, більш схожих на реальні ситуації. В кожному "профілі користувача" буде згенеровано від 40 до 50 іміджів за наступним принципом:

**Категорії:**
- **1 клас** - "любителі" певної категорії, кількість іміджів релевантних даній бізнес категорії 50% - 60%, інші 50% - інші бізнес категорії, чи нерелевантні іміджі
- **1 клас** - "користувачі" категорії, випадковим чином від 1 до 4 категорій, 15-25% на одну бізнес-категорію, решта - нерелевантні іміджі
- **1 клас** - шум, можливо до 5% на бізнес категорію, 80%+ - нерелевантного контенту

**Кількість профілів на 1 категорію (оціночно):**
- Якщо брати 500 профілів на 1 клас, то:
- 3 класи × 500 профілів × 45 (в середньому) іміджів = 60 000+ іміджів

**Модель**: Розроблена на 2-у етапі дослідження

по цьому експерименту розроблено код та проведено тестове обчислення для 100 профілів. В планах на наступний тиждень великий експеримент, обробка та інтерпритація результатів на 500 профілів на 1 клас = 1500 профілів

### 3.3. Четвертий експеримент: Пошук мінімальної кількості проявів бізнес-категорії, яких достатньо для класифікації ції бізнес-категорії

Третій експеримент має чітки межі між класами. По ходу дослідження з'явився інтерес знайти ту межу, яка відділяє шум від сигналу. 
